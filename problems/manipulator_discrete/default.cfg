# General-purpose settings.
#color = false
verbose = true

[problem]
logPath = /home/hoe01h/PhD/scripts/abt_newt/python/../problems/manipulator_discrete/log.log
policyPath = /home/hoe01h/PhD/scripts/abt_newt/python/../problems/manipulator_discrete/pol.pol
environment_path = /home/hoe01h/PhD/scripts/abt_newt/python/../problems/manipulator_discrete/environment/env_6dof.xml
robot_path = /home/hoe01h/PhD/scripts/abt_newt/python/../problems/manipulator_discrete/model/test_6dof.urdf

inc_covariance = observation

dynamicProblem = true
discountFactor = 0.999999

exitReward = 1000.0
illegalMovePenalty = 50.0
illegalActionPenalty = 50.0
stepPenalty = 1.0

process_covariance = 2.0
observation_covariance = 1.0
num_input_steps = 2

control_rate = 30.0

# The initial state of the robot. Has to be consistent with the number of degrees of freedom
init_state = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]

#halfEfficiencyDistance = 20

enforce_constraints = true

[DYNAMICS]
simulation_step_size = 0.001
gravity = 9.81

[RRT]
rrt_verb = false

# When a collision-free linear path can be constructed from the current state to the goal state,
# the linear path should be used (useRRTheuristic=false) instead of the RRT path.
check_linear_path = false
stretching_factor = 1.0
continuous_collision_check = false
planner = RRTConnect
planning_velocity = 6.0

[TRAJOPT]
use_trajopt = false
trajopt_points = 50
contact_distance = 0.15
penalty_distance = 0.14

[changes]
hasChanges = false
changesPath = changes/changes-7-8.txt
areDynamic = true

[ABT]
# The number of trajectories to simulate per time step (0 => wait for timeout)
historiesPerStep = 300000

# The maximum time to spend on each step, in milliseconds (0 => no time limit)
stepTimeout = 1000.0

# If this is set to "true", ABT will prune the tree after every step.
pruneEveryStep = false

# If this is set to "true", ABT will reset the tree instead of modifying it when
# changes occur.
resetOnChanges = false

# The particle filter to use
particleFilter = observationModel

# The minimum number of particles for the current belief state in a simulation.
# Extra particles will be resampled via a particle filter if the particle count
# for the *current* belief state drops below this number during simulation.
minParticleCount = 500

# Minimum number of effective particles below which resampling is happening
numEffectiveParticles = 1001

# Maximum number of particles tp plot
particlePlotLimit = 50

# Maximum time (in seconds) to replenish the particles
particleReplenishTimeout = 4.0

# The maximum depth to search in the tree, relative to the current belief.
maximumDepth = 100

maxObservationDistance = 300000.14

# True if the above horizon is relative to the initial belief, and false
# if it's relative to the current belief.
isAbsoluteHorizon = false

searchHeuristic = default()
searchStrategy = ucb(5.0)
estimator = max()

stateSamplingStrategy = default

numSamplesWeightedLazy = 10


[simulation]
loadInitialPolicy = false
savePolicy = false
saveParticles = false
nRuns = 1
nSteps = 100
showViewer = false
