# General-purpose settings.
color = false
verbose = true

[ABT]
# The number of trajectories to simulate per time step (0 => wait for timeout)
historiesPerStep = 0

# The maximum time to spend on each step, in milliseconds (0 => no time limit)
stepTimeout = 1000

# If this is set to "true", ABT will prune the tree after every step.
pruneEveryStep = true

# If this is set to "true", ABT will reset the tree instead of modifying it when
# changes occur.
resetOnChanges = false

# The minimum number of particles for the current belief state in a simulation.
# Extra particles will be resampled via a particle filter if the particle count
# for the *current* belief state drops below this number during simulation.
minParticleCount = 1000

# The maximum depth to search in the tree, relative to the current belief.
maximumDepth = 90
# True if the above horizon is relative to the initial belief, and false
# if it's relative to the current belief.
isAbsoluteHorizon = false

searchHeuristic = exactMdp()
searchStrategy = ucb(5.0)
estimator = mean()

[problem]
discountFactor = 0.95

mapPath = maps/map-11-11.txt
goodRockReward = 10
badRockPenalty = 10
exitReward = 10
illegalMovePenalty = 100
halfEfficiencyDistance = 20

[changes]
hasChanges = false
changesPath = changes/changes-11-11.txt
areDynamic = true

[heuristics]
# history-based heuristic type:
# none/legal/preferred
type = legal
# Restricted search: searches only the given category
# all / legal /preferred
search = legal
# Restricted rollout : randomly chooses from the given category
# all / legal / preferred
rollout = legal

# Initialises preferred actions to have biased initial q-values.
usePreferredInit = false
preferredQValue = 0.0
preferredVisitCount = 0

[simulation]
loadInitialPolicy = true
savePolicy = false
nSteps = 150
nRuns = 1
